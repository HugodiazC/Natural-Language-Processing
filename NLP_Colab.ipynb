{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1H-sp31aKtnHrgqyOS7tJbWzGjJrlxXBq",
      "authorship_tag": "ABX9TyMOFp4xTVx3Sk+sbxrEunIT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HugodiazC/Natural-Language-Processing/blob/main/NLP_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZUSgNVJrJEf"
      },
      "source": [
        "##¡Bienvenidos a esta clase de procesamiento de lenguaje natural!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLwAoTmgray-"
      },
      "source": [
        "import os\r\n",
        "import tweepy as tw\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "import string\r\n",
        "import pickle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBb5XAZmoH0w"
      },
      "source": [
        "Generar data set con Pandas\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzf5lQl_m1yE"
      },
      "source": [
        "tweet_text = pd.DataFrame(data=users_locs, \r\n",
        "                    columns=['user', \"location\"])\r\n",
        "tweet_text\r\n",
        "tweet_text['Tweets']=text_PRINT\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHoGioJ8rCrA"
      },
      "source": [
        "Limpieza del Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8icbeZpoTkn"
      },
      "source": [
        "def clean_text_round1(text):\r\n",
        "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\r\n",
        "    text = text.lower()\r\n",
        "    text = re.sub('\\[.*?\\]', '', text)\r\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\r\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\r\n",
        "    return text\r\n",
        "\r\n",
        "round1 = lambda text_PRINT: clean_text_round1(text_PRINT)\r\n",
        "\r\n",
        "def clean_text_round2(text):\r\n",
        "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\r\n",
        "    text = re.sub('[‘’“”…]', '', text)\r\n",
        "    text = re.sub('\\n', '', text)\r\n",
        "    return text\r\n",
        "\r\n",
        "round2 = lambda text_PRINT: clean_text_round2(text_PRINT)\r\n",
        "\r\n",
        "tweet_text['Tweets']=text_PRINT"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}